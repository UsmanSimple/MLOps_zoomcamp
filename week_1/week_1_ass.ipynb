{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!python --version"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python 3.9.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# import required libraries\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "#ignore warnings\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "# import the linear model and the feature extraction\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.feature_extraction import DictVectorizer\r\n",
    "\r\n",
    "# metrics\r\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#load the dataset\r\n",
    "train = pd.read_parquet('./Data/fhv_tripdata_2021-01.parquet')\r\n",
    "test = pd.read_parquet('./Data/fhv_tripdata_2021-02.parquet')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# display five 5 instances of the January/train data\r\n",
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00009 2021-01-01 00:27:00 2021-01-01 00:44:00           NaN   \n",
       "1               B00009 2021-01-01 00:50:00 2021-01-01 01:07:00           NaN   \n",
       "2               B00013 2021-01-01 00:01:00 2021-01-01 01:51:00           NaN   \n",
       "3               B00037 2021-01-01 00:13:09 2021-01-01 00:21:26           NaN   \n",
       "4               B00037 2021-01-01 00:38:31 2021-01-01 00:53:44           NaN   \n",
       "\n",
       "   DOlocationID SR_Flag Affiliated_base_number  \n",
       "0           NaN    None                 B00009  \n",
       "1           NaN    None                 B00009  \n",
       "2           NaN    None                 B00013  \n",
       "3          72.0    None                 B00037  \n",
       "4          61.0    None                 B00037  "
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1154112 entries, 0 to 1154111\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count    Dtype          \n",
      "---  ------                  --------------    -----          \n",
      " 0   dispatching_base_num    1154112 non-null  object         \n",
      " 1   pickup_datetime         1154112 non-null  datetime64[ns] \n",
      " 2   dropOff_datetime        1154112 non-null  datetime64[ns] \n",
      " 3   PUlocationID            195845 non-null   float64        \n",
      " 4   DOlocationID            991892 non-null   float64        \n",
      " 5   SR_Flag                 0 non-null        object         \n",
      " 6   Affiliated_base_number  1153227 non-null  object         \n",
      " 7   duration                1154112 non-null  timedelta64[ns]\n",
      "dtypes: datetime64[ns](2), float64(2), object(3), timedelta64[ns](1)\n",
      "memory usage: 70.4+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Q1- How many records are there in January data/ train dataframe\r\n",
    "print(f\"The size of the January/train dataset is {train.shape[0]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The size of the January/train dataset is 1154112\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Q2- Compute the duration in January\r\n",
    "train['duration'] = train['dropOff_datetime'] - train['pickup_datetime']\r\n",
    "test['duration'] = test['dropOff_datetime'] - test['pickup_datetime']\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Q2- Compute the average trip duration in January in minutes by dividing seconds by 60\r\n",
    "train['duration'] = train['duration'].apply(lambda x: x.total_seconds()/ 60 )\r\n",
    "test['duration'] = test['duration'].apply(lambda x: x.total_seconds()/ 60 )\r\n",
    "\r\n",
    "print('The average trip duration in January is {}'.format(train['duration'].mean()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average trip duration in January is 19.167224093791006\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Check the distribution of duration variable in January\r\n",
    "train.duration.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    1.154112e+06\n",
       "mean     1.916722e+01\n",
       "std      3.986922e+02\n",
       "min      1.666667e-02\n",
       "25%      7.766667e+00\n",
       "50%      1.340000e+01\n",
       "75%      2.228333e+01\n",
       "max      4.233710e+05\n",
       "Name: duration, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# The data attributes within the duration of 1 and 60 minutes inclusive\r\n",
    "df_train = train[(train['duration'] >= 1) & (train['duration']<= 60)]\r\n",
    "df_test = test[(test['duration'] >= 1) & (test['duration']<= 60)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Q2 - The number of records dropped\r\n",
    "print('The number of records dropped after outlier removal for January/Train data is : {}'.format(np.abs(len(train)-len(df_train)))) \r\n",
    "print('The number of records dropped after outlier removal for February/Test data is : {}'.format(np.abs(len(test)-len(df_test)))) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The number of records dropped after outlier removal for January/Train data is : 44286\n",
      "The number of records dropped after outlier removal for February/Test data is : 47579\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "train.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['dispatching_base_num', 'pickup_datetime', 'dropOff_datetime',\n",
       "       'PUlocationID', 'DOlocationID', 'SR_Flag', 'Affiliated_base_number',\n",
       "       'duration'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Q3 - Fractions of missing values in the data after selecting features to be used\r\n",
    "features_to_be_used = ['PUlocationID', 'DOlocationID']\r\n",
    "\r\n",
    "train_df = df_train[features_to_be_used]\r\n",
    "test_df = df_test[features_to_be_used]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# fill the null value with -1\r\n",
    "train_df.fillna(-1, inplace= True)\r\n",
    "test_df.fillna(-1, inplace=True)\r\n",
    "\r\n",
    "pickup_frac = ((train_df['PUlocationID'] == -1).sum() / len(train_df))* 100\r\n",
    "dropp_off_frac = ((test_df['DOlocationID'] == -1).sum() / len(test_df)) * 100\r\n",
    "\r\n",
    "# Q3 - Fractions of missing values in the data after selecting features to be used\r\n",
    "print('The fraction of missing values for the Pickup Location ID is : {}'.format(pickup_frac))\r\n",
    "print('The fraction of missing values for the Drop off Location ID is : {}'.format(dropp_off_frac))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The fraction of missing values for the Pickup Location ID is : 83.52732770722618\n",
      "The fraction of missing values for the Drop off Location ID is : 13.610567682678642\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Q4 - Dimensionality of the matrix after after one-hot encoding with DictVectorizer \r\n",
    "train_df = train_df.astype(str)\r\n",
    "test_df = test_df.astype(str)\r\n",
    "\r\n",
    "# Turn the dataframe into dictionary\r\n",
    "\r\n",
    "train_dict = train_df.to_dict(orient='records')\r\n",
    "test_dict =  test_df.to_dict(orient = 'records')\r\n",
    "\r\n",
    "vectorizer = DictVectorizer()\r\n",
    "X_train = vectorizer.fit_transform(train_dict)\r\n",
    "X_test = vectorizer.transform(test_dict)\r\n",
    "\r\n",
    "# dimension of the encoded feature\r\n",
    "print('The length of the encoded features is : {}'.format(len(vectorizer.feature_names_)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The length of the encoded features is : 525\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Q5 - Training a model and evaluating the model with RMSE\r\n",
    "y_train = df_train.duration.values\r\n",
    "y_test = df_test.duration.values\r\n",
    "\r\n",
    "lin_reg = LinearRegression()\r\n",
    "lin_reg.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred = lin_reg.predict(X_train)\r\n",
    "mean_squared_error(y_train, y_pred, squared=False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10.528519388409808"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "test_pred = lin_reg.predict(X_test)\r\n",
    "mean_squared_error(y_test, test_pred, squared= False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11.014287519486222"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "72d8f6e1992ab58b897e23a1d0f94879461b5cccafcce67f3b9899a0c6dd9b30"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}